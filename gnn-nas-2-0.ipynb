{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. INSTALL LIBRARIES (Robust Installation)\n!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cpu.html --quiet\n!pip install codecarbon --quiet\n\n# 2. IMPORT LIBRARIES AND DEFINE CLASSES\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport random\nimport copy\nimport pandas as pd\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool, global_max_pool, global_add_pool\nfrom torch_geometric.nn import BatchNorm, LayerNorm\nfrom codecarbon import EmissionsTracker\n\ndef set_seed(seed=42):\n    \"\"\"Sets the seed for reproducibility.\"\"\"\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass GNNSearchSpace:\n    \"\"\"Defines the search space for GNN architectures.\"\"\"\n    def __init__(self):\n        self.conv_type = ['GCN', 'GAT', 'SAGE']\n        self.pooling_type = ['mean', 'max', 'add']\n        self.activation = ['relu', 'elu', 'leaky_relu']\n        self.norm_type = ['batch', 'layer', 'none']\n        self.hidden_dim = [64, 128]\n        self.num_layers = [2, 3]\n        self.dropout = [0.2, 0.5]\n\n    def sample_architecture(self):\n        return {\n            'conv_type': random.choice(self.conv_type), 'pooling_type': random.choice(self.pooling_type),\n            'activation': random.choice(self.activation), 'norm_type': random.choice(self.norm_type),\n            'hidden_dim': random.choice(self.hidden_dim), 'num_layers': random.choice(self.num_layers),\n            'dropout': random.choice(self.dropout)\n        }\n\nclass GNNModel(nn.Module):\n    \"\"\"A dynamic GNN model built from a configuration dictionary.\"\"\"\n    def __init__(self, config, input_dim, output_dim):\n        super(GNNModel, self).__init__()\n        self.config = config; self.num_layers = config['num_layers']\n        self.convs = nn.ModuleList(); self.norms = nn.ModuleList()\n        in_dim, hidden_dim = input_dim, config['hidden_dim']\n\n        for i in range(self.num_layers):\n            out_dim = hidden_dim\n            if config['conv_type'] == 'GCN': conv = GCNConv(in_dim, out_dim)\n            elif config['conv_type'] == 'GAT': conv = GATConv(in_dim, out_dim, heads=1)\n            elif config['conv_type'] == 'SAGE': conv = SAGEConv(in_dim, out_dim)\n            self.convs.append(conv)\n            if i < self.num_layers - 1:\n                if config['norm_type'] == 'batch': norm = BatchNorm(out_dim)\n                elif config['norm_type'] == 'layer': norm = LayerNorm(out_dim)\n                else: norm = nn.Identity()\n                self.norms.append(norm)\n            in_dim = out_dim\n\n        if config['pooling_type'] == 'mean': self.pool = global_mean_pool\n        elif config['pooling_type'] == 'max': self.pool = global_max_pool\n        elif config['pooling_type'] == 'add': self.pool = global_add_pool\n        self.classifier = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x, edge_index, batch=None):\n        x = x.float()\n        for i in range(self.num_layers):\n            x = self.convs[i](x, edge_index)\n            if i < self.num_layers - 1:\n                x = self.norms[i](x)\n                if self.config['activation'] == 'relu': x = F.relu(x)\n                elif self.config['activation'] == 'elu': x = F.elu(x)\n                elif self.config['activation'] == 'leaky_relu': x = F.leaky_relu(x)\n                x = F.dropout(x, p=self.config['dropout'], training=self.training)\n        if batch is not None:\n            x = self.pool(x, batch)\n        x = self.classifier(x)\n        return x\n\ndef transfer_weights(parent_model, child_model):\n    \"\"\"Robustly transfers weights between compatible layers.\"\"\"\n    # Transfer convolutional layers\n    for i in range(min(len(parent_model.convs), len(child_model.convs))):\n        if type(parent_model.convs[i]) == type(child_model.convs[i]) and \\\n           parent_model.convs[i].in_channels == child_model.convs[i].in_channels and \\\n           parent_model.convs[i].out_channels == child_model.convs[i].out_channels:\n            child_model.convs[i].load_state_dict(parent_model.convs[i].state_dict())\n\n    # --- FIX: Add a shape check before copying normalization layer weights ---\n    for i in range(min(len(parent_model.norms), len(child_model.norms))):\n        parent_norm = parent_model.norms[i]\n        child_norm = child_model.norms[i]\n        if type(parent_norm) == type(child_norm) and hasattr(parent_norm, 'weight') and parent_norm.weight.shape == child_norm.weight.shape:\n             child_norm.load_state_dict(parent_norm.state_dict())\n    return child_model\n\nclass CarbonAwareGNNNAS:\n    \"\"\"The main class for the Neural Architecture Search.\"\"\"\n    def __init__(self, dataset_name='MUTAG', population_size=10, generations=5, seed=42):\n        set_seed(seed); self.dataset_name = dataset_name\n        self.population_size = population_size; self.generations = generations\n        self.search_space = GNNSearchSpace(); self.load_dataset()\n        self.best_overall_candidate = None\n\n    def load_dataset(self):\n        dataset = TUDataset(root=f'data/{self.dataset_name}', name=self.dataset_name)\n        self.input_dim = max(dataset.num_node_features, 1)\n        self.output_dim = dataset.num_classes\n        dataset = dataset.shuffle()\n        train_size = int(0.8 * len(dataset))\n        self.train_dataset, self.test_dataset = dataset[:train_size], dataset[train_size:]\n        self.train_loader = DataLoader(self.train_dataset, batch_size=32, shuffle=True)\n        self.test_loader = DataLoader(self.test_dataset, batch_size=32, shuffle=False)\n        print(f\"Dataset: {self.dataset_name} | Input: {self.input_dim} | Output: {self.output_dim}\")\n\n    def calculate_block_reuse(self, arch1, arch2):\n        if not arch1 or not arch2: return 0.0\n        return sum(1 for k in arch1 if arch1.get(k) == arch2.get(k)) / len(arch1)\n\n    def train_and_evaluate(self, model, parent_model=None, epochs=40):\n        if parent_model: model = transfer_weights(parent_model, model)\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        model.to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n        criterion = nn.CrossEntropyLoss()\n        tracker = EmissionsTracker(project_name=f\"gnn_nas_{self.dataset_name}\", log_level='error')\n        tracker.start()\n        for epoch in range(epochs):\n            model.train()\n            for batch in self.train_loader:\n                batch = batch.to(device)\n                optimizer.zero_grad()\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = criterion(out, batch.y); loss.backward(); optimizer.step()\n        emissions = tracker.stop()\n        model.eval()\n        correct = total = 0\n        with torch.no_grad():\n            for batch in self.test_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                pred = out.argmax(dim=1)\n                correct += (pred == batch.y).sum().item(); total += batch.y.size(0)\n        return {'accuracy': correct / total if total > 0 else 0.0, 'carbon': emissions if emissions else 0.0, 'model': model}\n\n    def mutate_architecture(self, base_config):\n        new_config = copy.deepcopy(base_config)\n        key_to_mutate = random.choice(list(base_config.keys()))\n        options = getattr(self.search_space, key_to_mutate)\n        new_config[key_to_mutate] = random.choice(options)\n        return new_config\n\n    def tournament_selection(self, population, k=3):\n        best = None\n        for _ in range(k):\n            ind = random.choice(population)\n            if best is None or ind['score'] > best['score']: best = ind\n        return best\n\n    def run_search(self):\n        print(\"Starting Carbon-Aware GNN NAS...\")\n        population = []\n        \n        print(\"\\n--- Training fixed baseline model ---\")\n        baseline_config = {'conv_type': 'GCN', 'pooling_type': 'mean', 'activation': 'relu', 'norm_type': 'batch', 'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.2}\n        baseline_model = GNNModel(baseline_config, self.input_dim, self.output_dim)\n        baseline_result = self.train_and_evaluate(baseline_model, epochs=50)\n        print(f\"  Baseline Results: Acc={baseline_result['accuracy']:.4f}, Carbon={baseline_result['carbon']:.6f} kg\")\n        \n        print(\"\\n--- Generation 0: Initial Population ---\")\n        for i in range(self.population_size):\n            config = self.search_space.sample_architecture()\n            model = GNNModel(config, self.input_dim, self.output_dim)\n            result = self.train_and_evaluate(model, epochs=40)\n            population.append({'config': config, 'parent_config': None, 'score': 0, 'accuracy': result['accuracy'], 'carbon': result['carbon'], 'model': result['model']})\n            print(f\"  Candidate {i+1}: Acc={result['accuracy']:.4f}, Carbon={result['carbon']:.6f}\")\n        \n        for gen in range(1, self.generations + 1):\n            print(f\"\\n--- Generation {gen}/{self.generations} ---\")\n            for cand in population:\n                reuse_score = self.calculate_block_reuse(cand['config'], cand['parent_config'])\n                carbon_score = 1 - min(cand['carbon'] * 1e4, 1.0)\n                cand['score'] = 0.6 * cand['accuracy'] + 0.3 * carbon_score + 0.1 * reuse_score\n                cand['reuse'] = reuse_score\n            population.sort(key=lambda x: x['score'], reverse=True)\n            if self.best_overall_candidate is None or population[0]['score'] > self.best_overall_candidate['score']:\n                self.best_overall_candidate = population[0]\n            print(f\"  Best of Gen {gen-1}: Acc={population[0]['accuracy']:.4f}, Carbon={population[0]['carbon']:.6f}, Reuse={population[0]['reuse']:.3f}, Score={population[0]['score']:.4f}\")\n            next_generation = [population[0]]\n            while len(next_generation) < self.population_size:\n                parent = self.tournament_selection(population)\n                child_config = self.mutate_architecture(parent['config'])\n                child_model = GNNModel(child_config, self.input_dim, self.output_dim)\n                result = self.train_and_evaluate(child_model, parent_model=parent['model'], epochs=30)\n                next_generation.append({'config': child_config, 'parent_config': parent['config'], 'score': 0, 'accuracy': result['accuracy'], 'carbon': result['carbon'], 'model': result['model']})\n            population = next_generation\n\n        print(\"\\n--- Search Complete. Final Evaluation ---\")\n        best_config = self.best_overall_candidate['config']\n        print(\"Retraining best architecture on full data for 100 epochs...\")\n        final_model = GNNModel(best_config, self.input_dim, self.output_dim)\n        final_result = self.train_and_evaluate(final_model, epochs=100)\n        \n        print(\"\\n--- Final Results ---\")\n        print(f\"Best Architecture: {best_config}\")\n        print(f\"Final Test Accuracy: {final_result['accuracy']:.4f}\")\n        print(f\"Carbon Footprint (Final Train): {final_result['carbon']:.6f} kg CO2\")\n        print(f\"Block Reuse Score (vs. baseline): {self.calculate_block_reuse(best_config, baseline_config):.3f}\")\n\n# 3. RUN THE EXPERIMENT\nif __name__ == \"__main__\":\n    nas = CarbonAwareGNNNAS(dataset_name='MUTAG', population_size=10, generations=5)\n    nas.run_search()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:07:45.012486Z","iopub.execute_input":"2025-10-26T15:07:45.013306Z","iopub.status.idle":"2025-10-26T15:13:01.624503Z","shell.execute_reply.started":"2025-10-26T15:07:45.013276Z","shell.execute_reply":"2025-10-26T15:13:01.623773Z"}},"outputs":[{"name":"stdout","text":"Dataset: MUTAG | Input: 7 | Output: 2\nStarting Carbon-Aware GNN NAS...\n\n--- Training fixed baseline model ---\n  Baseline Results: Acc=0.6842, Carbon=0.000018 kg\n\n--- Generation 0: Initial Population ---\n  Candidate 1: Acc=0.6316, Carbon=0.000012\n  Candidate 2: Acc=0.6579, Carbon=0.000016\n  Candidate 3: Acc=0.6842, Carbon=0.000014\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Candidate 4: Acc=0.4474, Carbon=0.000015\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Candidate 5: Acc=0.6842, Carbon=0.000018\n  Candidate 6: Acc=0.6842, Carbon=0.000019\n  Candidate 7: Acc=0.7105, Carbon=0.000015\n  Candidate 8: Acc=0.6842, Carbon=0.000014\n  Candidate 9: Acc=0.6842, Carbon=0.000019\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Candidate 10: Acc=0.7368, Carbon=0.000018\n\n--- Generation 1/5 ---\n  Best of Gen 0: Acc=0.7368, Carbon=0.000018, Reuse=0.000, Score=0.6872\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Generation 2/5 ---\n  Best of Gen 1: Acc=0.7105, Carbon=0.000010, Reuse=1.000, Score=0.7950\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Generation 3/5 ---\n  Best of Gen 2: Acc=0.7368, Carbon=0.000011, Reuse=1.000, Score=0.8089\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Generation 4/5 ---\n  Best of Gen 3: Acc=0.7368, Carbon=0.000011, Reuse=1.000, Score=0.8089\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Generation 5/5 ---\n  Best of Gen 4: Acc=0.7368, Carbon=0.000011, Reuse=1.000, Score=0.8089\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n--- Search Complete. Final Evaluation ---\nRetraining best architecture on full data for 100 epochs...\n\n--- Final Results ---\nBest Architecture: {'conv_type': 'SAGE', 'pooling_type': 'add', 'activation': 'elu', 'norm_type': 'batch', 'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.2}\nFinal Test Accuracy: 0.7105\nCarbon Footprint (Final Train): 0.000038 kg CO2\nBlock Reuse Score (vs. baseline): 0.286\n","output_type":"stream"}],"execution_count":7}]}